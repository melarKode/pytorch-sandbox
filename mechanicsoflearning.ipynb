{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2123df19580>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_u,t_c, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w*t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    return ((t_p-t_c)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.ones(())\n",
    "b = torch.zeros(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = model(t_u,w,b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rate_of_change_w = (loss_fn(model(t_u,w+delta,b),t_c)-loss_fn(model(t_u,w-delta,b),t_c))/(2.0*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2    \n",
    "w = w-learning_rate*loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rate_of_change_b = (loss_fn(model(t_u,w,b+delta),t_c)-loss_fn(model(t_u,w,b-delta),t_c))/(2.0*delta)\n",
    "b = b-learning_rate*loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    return 2*(t_p-t_c)/t_p.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(t_u,w,b):\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u,w,b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(t_u,t_c,t_p,w,b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp*dmodel_dw(t_u,w,b)\n",
    "    dloss_db = dloss_dtp*dmodel_db(t_u,w,b)\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs,learning_rate,params,t_u,t_c):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        w,b = params\n",
    "        t_p = model(t_u,w,b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u,t_c,t_p,w,b)\n",
    "\n",
    "        params = params - learning_rate*grad\n",
    "        print('Epoch: {}, Loss: {:.2f}, Params: {}'.format(epoch, loss.item(), params))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1763.88, Params: tensor([ 0.5483, -0.0083])\n",
      "Epoch: 2, Loss: 323.09, Params: tensor([ 0.3623, -0.0118])\n",
      "Epoch: 3, Loss: 78.93, Params: tensor([ 0.2858, -0.0135])\n",
      "Epoch: 4, Loss: 37.55, Params: tensor([ 0.2543, -0.0143])\n",
      "Epoch: 5, Loss: 30.54, Params: tensor([ 0.2413, -0.0149])\n",
      "Epoch: 6, Loss: 29.35, Params: tensor([ 0.2360, -0.0153])\n",
      "Epoch: 7, Loss: 29.15, Params: tensor([ 0.2338, -0.0156])\n",
      "Epoch: 8, Loss: 29.11, Params: tensor([ 0.2329, -0.0159])\n",
      "Epoch: 9, Loss: 29.11, Params: tensor([ 0.2325, -0.0162])\n",
      "Epoch: 10, Loss: 29.11, Params: tensor([ 0.2324, -0.0166])\n",
      "Epoch: 11, Loss: 29.10, Params: tensor([ 0.2323, -0.0169])\n",
      "Epoch: 12, Loss: 29.10, Params: tensor([ 0.2323, -0.0172])\n",
      "Epoch: 13, Loss: 29.10, Params: tensor([ 0.2323, -0.0175])\n",
      "Epoch: 14, Loss: 29.10, Params: tensor([ 0.2323, -0.0178])\n",
      "Epoch: 15, Loss: 29.10, Params: tensor([ 0.2323, -0.0181])\n",
      "Epoch: 16, Loss: 29.10, Params: tensor([ 0.2323, -0.0184])\n",
      "Epoch: 17, Loss: 29.10, Params: tensor([ 0.2323, -0.0187])\n",
      "Epoch: 18, Loss: 29.10, Params: tensor([ 0.2323, -0.0190])\n",
      "Epoch: 19, Loss: 29.10, Params: tensor([ 0.2323, -0.0193])\n",
      "Epoch: 20, Loss: 29.10, Params: tensor([ 0.2323, -0.0196])\n",
      "Epoch: 21, Loss: 29.09, Params: tensor([ 0.2323, -0.0199])\n",
      "Epoch: 22, Loss: 29.09, Params: tensor([ 0.2323, -0.0202])\n",
      "Epoch: 23, Loss: 29.09, Params: tensor([ 0.2323, -0.0205])\n",
      "Epoch: 24, Loss: 29.09, Params: tensor([ 0.2323, -0.0208])\n",
      "Epoch: 25, Loss: 29.09, Params: tensor([ 0.2323, -0.0211])\n",
      "Epoch: 26, Loss: 29.09, Params: tensor([ 0.2323, -0.0214])\n",
      "Epoch: 27, Loss: 29.09, Params: tensor([ 0.2323, -0.0217])\n",
      "Epoch: 28, Loss: 29.09, Params: tensor([ 0.2323, -0.0220])\n",
      "Epoch: 29, Loss: 29.09, Params: tensor([ 0.2323, -0.0223])\n",
      "Epoch: 30, Loss: 29.09, Params: tensor([ 0.2323, -0.0226])\n",
      "Epoch: 31, Loss: 29.09, Params: tensor([ 0.2324, -0.0229])\n",
      "Epoch: 32, Loss: 29.08, Params: tensor([ 0.2324, -0.0232])\n",
      "Epoch: 33, Loss: 29.08, Params: tensor([ 0.2324, -0.0235])\n",
      "Epoch: 34, Loss: 29.08, Params: tensor([ 0.2324, -0.0238])\n",
      "Epoch: 35, Loss: 29.08, Params: tensor([ 0.2324, -0.0241])\n",
      "Epoch: 36, Loss: 29.08, Params: tensor([ 0.2324, -0.0244])\n",
      "Epoch: 37, Loss: 29.08, Params: tensor([ 0.2324, -0.0247])\n",
      "Epoch: 38, Loss: 29.08, Params: tensor([ 0.2324, -0.0250])\n",
      "Epoch: 39, Loss: 29.08, Params: tensor([ 0.2324, -0.0253])\n",
      "Epoch: 40, Loss: 29.08, Params: tensor([ 0.2324, -0.0256])\n",
      "Epoch: 41, Loss: 29.08, Params: tensor([ 0.2324, -0.0259])\n",
      "Epoch: 42, Loss: 29.08, Params: tensor([ 0.2324, -0.0262])\n",
      "Epoch: 43, Loss: 29.07, Params: tensor([ 0.2324, -0.0265])\n",
      "Epoch: 44, Loss: 29.07, Params: tensor([ 0.2324, -0.0268])\n",
      "Epoch: 45, Loss: 29.07, Params: tensor([ 0.2324, -0.0271])\n",
      "Epoch: 46, Loss: 29.07, Params: tensor([ 0.2324, -0.0274])\n",
      "Epoch: 47, Loss: 29.07, Params: tensor([ 0.2324, -0.0277])\n",
      "Epoch: 48, Loss: 29.07, Params: tensor([ 0.2324, -0.0281])\n",
      "Epoch: 49, Loss: 29.07, Params: tensor([ 0.2325, -0.0284])\n",
      "Epoch: 50, Loss: 29.07, Params: tensor([ 0.2325, -0.0287])\n",
      "Epoch: 51, Loss: 29.07, Params: tensor([ 0.2325, -0.0290])\n",
      "Epoch: 52, Loss: 29.07, Params: tensor([ 0.2325, -0.0293])\n",
      "Epoch: 53, Loss: 29.07, Params: tensor([ 0.2325, -0.0296])\n",
      "Epoch: 54, Loss: 29.06, Params: tensor([ 0.2325, -0.0299])\n",
      "Epoch: 55, Loss: 29.06, Params: tensor([ 0.2325, -0.0302])\n",
      "Epoch: 56, Loss: 29.06, Params: tensor([ 0.2325, -0.0305])\n",
      "Epoch: 57, Loss: 29.06, Params: tensor([ 0.2325, -0.0308])\n",
      "Epoch: 58, Loss: 29.06, Params: tensor([ 0.2325, -0.0311])\n",
      "Epoch: 59, Loss: 29.06, Params: tensor([ 0.2325, -0.0314])\n",
      "Epoch: 60, Loss: 29.06, Params: tensor([ 0.2325, -0.0317])\n",
      "Epoch: 61, Loss: 29.06, Params: tensor([ 0.2325, -0.0320])\n",
      "Epoch: 62, Loss: 29.06, Params: tensor([ 0.2325, -0.0323])\n",
      "Epoch: 63, Loss: 29.06, Params: tensor([ 0.2325, -0.0326])\n",
      "Epoch: 64, Loss: 29.06, Params: tensor([ 0.2325, -0.0329])\n",
      "Epoch: 65, Loss: 29.05, Params: tensor([ 0.2325, -0.0332])\n",
      "Epoch: 66, Loss: 29.05, Params: tensor([ 0.2325, -0.0335])\n",
      "Epoch: 67, Loss: 29.05, Params: tensor([ 0.2325, -0.0338])\n",
      "Epoch: 68, Loss: 29.05, Params: tensor([ 0.2326, -0.0341])\n",
      "Epoch: 69, Loss: 29.05, Params: tensor([ 0.2326, -0.0344])\n",
      "Epoch: 70, Loss: 29.05, Params: tensor([ 0.2326, -0.0347])\n",
      "Epoch: 71, Loss: 29.05, Params: tensor([ 0.2326, -0.0350])\n",
      "Epoch: 72, Loss: 29.05, Params: tensor([ 0.2326, -0.0353])\n",
      "Epoch: 73, Loss: 29.05, Params: tensor([ 0.2326, -0.0356])\n",
      "Epoch: 74, Loss: 29.05, Params: tensor([ 0.2326, -0.0359])\n",
      "Epoch: 75, Loss: 29.05, Params: tensor([ 0.2326, -0.0362])\n",
      "Epoch: 76, Loss: 29.04, Params: tensor([ 0.2326, -0.0365])\n",
      "Epoch: 77, Loss: 29.04, Params: tensor([ 0.2326, -0.0368])\n",
      "Epoch: 78, Loss: 29.04, Params: tensor([ 0.2326, -0.0371])\n",
      "Epoch: 79, Loss: 29.04, Params: tensor([ 0.2326, -0.0374])\n",
      "Epoch: 80, Loss: 29.04, Params: tensor([ 0.2326, -0.0377])\n",
      "Epoch: 81, Loss: 29.04, Params: tensor([ 0.2326, -0.0380])\n",
      "Epoch: 82, Loss: 29.04, Params: tensor([ 0.2326, -0.0383])\n",
      "Epoch: 83, Loss: 29.04, Params: tensor([ 0.2326, -0.0386])\n",
      "Epoch: 84, Loss: 29.04, Params: tensor([ 0.2326, -0.0389])\n",
      "Epoch: 85, Loss: 29.04, Params: tensor([ 0.2326, -0.0392])\n",
      "Epoch: 86, Loss: 29.04, Params: tensor([ 0.2326, -0.0395])\n",
      "Epoch: 87, Loss: 29.03, Params: tensor([ 0.2327, -0.0398])\n",
      "Epoch: 88, Loss: 29.03, Params: tensor([ 0.2327, -0.0401])\n",
      "Epoch: 89, Loss: 29.03, Params: tensor([ 0.2327, -0.0405])\n",
      "Epoch: 90, Loss: 29.03, Params: tensor([ 0.2327, -0.0408])\n",
      "Epoch: 91, Loss: 29.03, Params: tensor([ 0.2327, -0.0411])\n",
      "Epoch: 92, Loss: 29.03, Params: tensor([ 0.2327, -0.0414])\n",
      "Epoch: 93, Loss: 29.03, Params: tensor([ 0.2327, -0.0417])\n",
      "Epoch: 94, Loss: 29.03, Params: tensor([ 0.2327, -0.0420])\n",
      "Epoch: 95, Loss: 29.03, Params: tensor([ 0.2327, -0.0423])\n",
      "Epoch: 96, Loss: 29.03, Params: tensor([ 0.2327, -0.0426])\n",
      "Epoch: 97, Loss: 29.03, Params: tensor([ 0.2327, -0.0429])\n",
      "Epoch: 98, Loss: 29.02, Params: tensor([ 0.2327, -0.0432])\n",
      "Epoch: 99, Loss: 29.02, Params: tensor([ 0.2327, -0.0435])\n",
      "Epoch: 100, Loss: 29.02, Params: tensor([ 0.2327, -0.0438])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2327, -0.0438])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(100,1e-4,torch.tensor([1.0,0.0]),t_u,t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u,w,b):\n",
    "    return w*t_u+b\n",
    "def loss_fn(t_p,t_c):\n",
    "    return ((t_p-t_c)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0,0.0],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(t_u,*params),t_c)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u,*params),t_c)\n",
    "loss.backward()\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, learning_rate,params,t_u,t_c):\n",
    "    for epoch in range(epochs):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        t_p = model(t_u,*params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate*params.grad\n",
    "        if epoch%500==0:\n",
    "            print('Epoch: {}, Loss: {:.2f}'.format(epoch, loss.item()))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 80.36\n",
      "Epoch: 500, Loss: 7.84\n",
      "Epoch: 1000, Loss: 3.83\n",
      "Epoch: 1500, Loss: 3.09\n",
      "Epoch: 2000, Loss: 2.96\n",
      "Epoch: 2500, Loss: 2.93\n",
      "Epoch: 3000, Loss: 2.93\n",
      "Epoch: 3500, Loss: 2.93\n",
      "Epoch: 4000, Loss: 2.93\n",
      "Epoch: 4500, Loss: 2.93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(5000,1e-2, torch.tensor([1.0,0.0], requires_grad=True),t_u*0.1,t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional',\n",
       " '_multi_tensor',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0,0.0],requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params],lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = model(t_u,*params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7761, 0.1064], requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0,0.0],requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params],learning_rate)\n",
    "t_p = model(t_u*0.1,*params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(n_epochs):\n",
    "        t_p = model(t_u,*params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch%500==0:\n",
    "            print('Epoch: {}, Loss: {:.2f}'.format(epoch, loss.item()))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1763.88\n",
      "Epoch: 500, Loss: 25.59\n",
      "Epoch: 1000, Loss: 22.95\n",
      "Epoch: 1500, Loss: 19.63\n",
      "Epoch: 2000, Loss: 16.02\n",
      "Epoch: 2500, Loss: 12.48\n",
      "Epoch: 3000, Loss: 9.33\n",
      "Epoch: 3500, Loss: 6.80\n",
      "Epoch: 4000, Loss: 4.99\n",
      "Epoch: 4500, Loss: 3.87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5017, -15.3177], requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.,0.],requires_grad=True)\n",
    "learning_rate=1e-2\n",
    "optimizer = optim.Adam([params],learning_rate)\n",
    "training_loop(5000,optimizer,params,t_u,t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37949852516ccaa153c0024f6d4d7ac0036053c674905739b9a34c73111dd78b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
